---
name: "Resume"
permalink: /resume/
layout: single
print_style: true
---

# Suyeong Kim 
<p style="text-align: center;"> sy.from.kr@gmail.com | hello-iam-sy.github.io | Sydney, NSW</p>


## CAREER PROFILE  

I started my career as a **data engineer**, working on building and maintaining data platforms. Most of my work involved **enhancing data usability and accessibility and ensuring the reliability of datasets**.

I am pursuing a **Master of Professional Engineering in Software Engineering** at The University of Sydney. I came to Australia because I wanted to push myself technically—learning not just about data, but also about **high-performance computing and real-time processing** to enable real-time, data-driven decision-making.

That’s why I’m interested in **Citadel Securities**. I want to be in a place where technology is at the core of decision-making. I’d love the opportunity to be part of that and contribute in a meaningful way.

## EDUCATION 

<div style="display: flex; justify-content: space-between;">
  <span>
    <span>Master of Computer Science</span><br>
    <span>The University of Sydney</span>
  </span>
  <span style="font-size: 12px;">February 2025 - expected Dec 2026</span>
</div>

<div style="display: flex; justify-content: space-between; margin-bottom: 20px;">
  <span>
    <span>Bachelor in Mechanical and System Design Engineering</span><br>
    <span>Hongik University</span>
  </span>
  <span style="font-size: 12px;">March 2014 - August 2019</span>
</div>

## RELEVANT EXPERIENCE  

<div style="display: flex; justify-content: space-between; margin-bottom: 10px; font-size: 18px;">
  <span>
    <strong>LGCNS</strong><br>
  </span>
  <span style="font-size: 12px;">Seoul, Republic of Korea</span>
</div>

<div style="display: flex; justify-content: space-between; margin-bottom: 20px; font-size: 16px;">
  <span>
    <strong>Data Platform Architecture Team / Data Engineer</strong><br>
  </span>
  <span style="font-size: 12px;">July 2019 - October 2024</span>
</div>

### Implementation of New Big Data Platform Components
- Designed and integrated **metadata management and data lineage tracking systems** using **DataHub** to enhance transparency and traceability.
- Modified **container-based deployment** (originally Docker/Kubernetes) to function in an **on-premise environment**, optimizing **metadata management**.
- Connected **S3, Hive, Delta Lake, and PostgreSQL** to DataHub, improving **data discoverability and quality control**.
- Developed concise **API documentation and internal usage guides**, ensuring smooth adoption by data teams.
- **Technologies used**: Python, DataHub, Hadoop, Ambari, Docker, Shell  

### Data API Testing and Validation
- Developed and tested **API-driven data pipelines** to ensure secure, high-speed access to large-scale datasets.
- Simulated **AWS-like API behavior** for an **on-premise data platform**, integrating services like **HDFS, S3, GreenPlum DB, and DynamoDB**.
- **Technologies used**: Python, Pandas, HDFS, S3, GreenPlum DB, Hive, Athena  

### Home Appliance Demand Forecasting Service
- Maintained and optimized **forecasting models for demand prediction**, ensuring accurate weekly updates.
- Collaborated with data scientists to **enhance machine learning models** by integrating **new data features**.
- Built an **automated Slack-based alerting system** for real-time monitoring of **ETL pipelines**.
- **Technologies used**: Informatica, BigQuery, Python, Pandas  

## TECHNICAL SKILLS  
**Programming Languages**: Python, SQL, Shell  
**Data Engineering**: Hadoop, Kafka, Spark, ETL Pipelines, API Development  
**Cloud Platforms**: AWS, GCP  
**Languages**: Korean (Native), English (Proficient)