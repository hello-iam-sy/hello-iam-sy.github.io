---
title: "Kafka mini project"
date: 2024-12-24
last_modified_at: 2024-12-24
categories:
  - kafka
toc: true
toc_sticky: true
toc_label: "On This Page"
---

### Kafka mini project
인프런에서 강의를 다 들은 기념으로 미니프로젝트를 해보려 한다.  
application 에서 로그가 쌓이면, 이를 카프카에서 가져가고, aggregation 한 뒤, API 를 통해 데이터를 가져갈 수 있도록 한다.

#### 로그 생성 조건

1. **랜덤하게 초당 10건의 로그를 생성한다.**
   - 각 로그는 `TIMESTAMP`, `EVENT_TYPE`, `USER_ID`, `MESSAGE` 필드를 포함한다.
   - 로그 데이터는 이벤트 유형과 메시지의 논리적 일관성을 유지한다.

2. **로그는 단일 log 파일로 생성된다.**
   - 하나의 파일에 로그가 계속해서 추가(append)된다.

3. **로그 파일은 날짜별로 생성된다.**
   - 파일 이름은 날짜별로 `/{yyyymmdd}.log` 형식으로 생성된다.
   - **예시**: `20241224.log`

4. **로그 데이터 형식은 다음과 같다.**
   - `"[$TIMESTAMP] [$EVENT_TYPE] [user_id:$USER_ID] $MESSAGE"`
   - **예시**:
     ```plaintext
     [2024-12-24 15:10:01.123] [INFO] [user_id:user123] User logged in successfully.
     [2024-12-24 15:10:01.456] [WARN] [user_id:user456] Disk usage exceeds 80%.
     [2024-12-24 15:10:01.789] [ERROR] [user_id:user789] Database connection timeout.
     ```

5. **로그 생성 방식**
   - `EVENT_TYPE`과 `MESSAGE`는 서로 매칭되어야 한다.
     - **INFO** → `"User logged in successfully."`
     - **WARN** → `"Disk usage exceeds 80%."`
     - **ERROR** → `"Database connection timeout."`

6. **저장 경로**
   - 로그 파일은 현재 디렉토리의 `logs` 하위 디렉토리에 저장된다.
   - **예시**: `./logs/20241224.log`

**log-generator.sh**  
```bash
#!/bin/sh

# 로그 파일 저장 경로
LOG_DIR="/logs"
DATE=$(date +"%Y%m%d")
LOG_FILE="$LOG_DIR/$DATE.log"

# 로그 디렉토리 생성
mkdir -p $LOG_DIR

# 데이터 생성 함수
generate_log() {
  TIMESTAMP=$(date +"%Y-%m-%d %H:%M:%S.%3N")  # 밀리초 포함 타임스탬프

  # 사용자 ID 목록
  USER_IDS="user123 user456 user789"
  # 이벤트 타입 목록
  EVENT_TYPES="INFO WARN ERROR"

  # 랜덤 데이터 생성
  USER_ID=$(echo $USER_IDS | tr " " "\n" | shuf -n 1)  # 랜덤 사용자 ID
  EVENT_TYPE=$(echo $EVENT_TYPES | tr " " "\n" | shuf -n 1)  # 랜덤 이벤트 타입

  # 이벤트 타입에 따른 메시지 매핑
  case $EVENT_TYPE in
    "INFO")
      MESSAGE="User logged in successfully." ;;
    "WARN")
      MESSAGE="Disk usage exceeds 80%." ;;
    "ERROR")
      MESSAGE="Database connection timeout." ;;
    *)
      MESSAGE="Unknown event." ;;
  esac

  # 로그 데이터 생성
  LOG="[$TIMESTAMP] [$EVENT_TYPE] [user_id:$USER_ID] $MESSAGE"
  echo $LOG >> $LOG_FILE
  echo $LOG
}

# 초당 10건의 로그 생성
echo "Generating logs at 10 logs per second... Press [CTRL+C] to stop."
while true; do
  for i in $(seq 1 10); do
    generate_log &
  done
  wait
  sleep 1
done

```

#### docker compose yml 파일 작성
```
version: "3.8"
services:
  generator:
    container_name: generator
    image: alpine:3.18
    volumes:
      - ./generator/logs:/logs                       
      - ./generator/log-generator.sh:/log-generator.sh 
    working_dir: /                                   
    command: sh /log-generator.sh # 패키지 설치 후 스크립트 실행

```
### 프로젝트 directory 구조
```
kafka-pjt
├── generator
│   ├── log-generator.sh
│   └── logs
│       └── 20241224.log
└── kafka-pjt.yml
```
